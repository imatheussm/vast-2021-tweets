{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vast Mini Challenge 03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook aims to perform an exploratory analysis of the data from the _VAST Mini Challenge 03_, in order to answer the three questions proposed through data visualization. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The .csv and .geojson files of the Abila map were obtained from the conversion of the files provided by the mini challenge (present in the Abila folder) using the tool https://mapshaper.org. Just access the site, send the Abila folder with the 4 files inside and click export as .csv and .geojson. \n",
    "\n",
    "With the geojson obtained, the code from the **geocode.js** file was used, which loads the geojson file of the Abila map and the csv file of reports. With that, it was iterated about the locations of the reports and obtained their coordinates. After that, a .json file with the coordinates was obtained. This .json is called **coordinates.json**\n",
    "\n",
    "All these generated files are in the folder _abilaMap_processed_. \n",
    "\n",
    "**Attention**: it takes a few steps to run the js code used to generate the files. However, let's skip these steps and use the files already generated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy as sp\n",
    "from datetime import datetime\n",
    "from nltk.corpus import stopwords\n",
    "import plotly.express as px\n",
    "import altair as alt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abila Map: Locations' Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>coords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Egeou St / Parla St</td>\n",
       "      <td>[24.85526400000002, 36.05022]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N. Els St / N. Polvo St</td>\n",
       "      <td>[24.871374000000017, 36.051901]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2099 Sannan Pky</td>\n",
       "      <td>[24.89820500000002, 36.069383]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3654 N. Barwyn St</td>\n",
       "      <td>[24.875345818181838, 36.07422]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3815 N. Blant St</td>\n",
       "      <td>[24.87282157575759, 36.07712]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Exadakitiou Way / Rist Way</td>\n",
       "      <td>[24.882564000000016, 36.07542]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>N. Limnou St / N. Alm St</td>\n",
       "      <td>[24.856464000000017, 36.06032]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>2299 N. Finiatur St</td>\n",
       "      <td>[24.85096400000002, 36.06342]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>S. Mikonou St / S. Achilleos St</td>\n",
       "      <td>[24.870004000000023, 36.045235]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>N. Pilau St / N. Diogenous St</td>\n",
       "      <td>[24.844486000000018, 36.090919]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            location                           coords\n",
       "0                Egeou St / Parla St    [24.85526400000002, 36.05022]\n",
       "1            N. Els St / N. Polvo St  [24.871374000000017, 36.051901]\n",
       "2                    2099 Sannan Pky   [24.89820500000002, 36.069383]\n",
       "3                  3654 N. Barwyn St   [24.875345818181838, 36.07422]\n",
       "4                   3815 N. Blant St    [24.87282157575759, 36.07712]\n",
       "..                               ...                              ...\n",
       "147       Exadakitiou Way / Rist Way   [24.882564000000016, 36.07542]\n",
       "148         N. Limnou St / N. Alm St   [24.856464000000017, 36.06032]\n",
       "149              2299 N. Finiatur St    [24.85096400000002, 36.06342]\n",
       "150  S. Mikonou St / S. Achilleos St  [24.870004000000023, 36.045235]\n",
       "151    N. Pilau St / N. Diogenous St  [24.844486000000018, 36.090919]\n",
       "\n",
       "[152 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords = pd.read_json(\"abilaMap_processed/coordinates.json\")\n",
    "\n",
    "coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "The preprocessing includes punctuation and stopword removal and lemmatization. After that, calls ('ccdata' type) and posts ('mbdata' type) are separated into different files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the appropriate model\n",
    "#\n",
    "# Before doing so, they need to be installed. Choose one (or both, for safe measure) of them:\n",
    "#  - Bigger, slower, but more accurate: python -m spacy download en_core_web_trf\n",
    "#  - Small, faster, but less accurate: python -m spacy download en_core_web_sm\n",
    "nlp = sp.load(\"en_core_web_trf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/3] Processing data-frames...\n",
      " |_ [1033/1033] Processing completed.\n",
      "[2/3] Processing data-frames...\n",
      " |_ [1815/1815] Processing completed.\n",
      "[3/3] Processing data-frames...\n",
      " |_ [1215/1215] Processing completed.\n"
     ]
    }
   ],
   "source": [
    "# Loading and preprocessing the data sets.\n",
    "#\n",
    "# Time periods:\n",
    "#  - Period one: 1700-1830\n",
    "#  - Period two: 1831-2000\n",
    "#  - Period three: 2001-2131\n",
    "\n",
    "periods = (\"1700-1830\", \"1831-2000\", \"2001-2131\")\n",
    "data_frames = [pd.read_csv(f\"original_csv/csv-{period}.csv\") for period in periods]\n",
    "stop_words = stopwords.words(\"english\")\n",
    "\n",
    "for index, data_frame in enumerate(data_frames):\n",
    "    print(f\"[{index + 1}/{len(data_frames)}] Processing data-frames...\")\n",
    "    data_frame_length = data_frame.shape[0]\n",
    "\n",
    "    for row in range(data_frame_length):\n",
    "        print(f\" |_ [{row + 1}/{data_frame_length}] Processing row...\", end=\"\\r\")\n",
    "\n",
    "        message = data_frame.loc[row, \"message\"]\n",
    "        document = nlp(message)\n",
    "        tokens = [\n",
    "            token.lemma_ for token in document\n",
    "            if token.text not in stop_words  # Remove stop words\n",
    "            and token.is_punct is False      # Remove punctuation\n",
    "        ]\n",
    "\n",
    "        data_frame.loc[row, \"message\"] = \" \".join(tokens)\n",
    "\n",
    "    print(f\" |_ [{data_frame_length}/{data_frame_length}] Processing completed.\")\n",
    "\n",
    "combined_csv = pd.concat(data_frames)\n",
    "combined_csv.to_csv(\"processed/combined_csv.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate posts and calls (reports)\n",
    "combined_csv = pd.read_csv(\"processed/combined_csv.csv\")\n",
    "combined_csv['timestamp'] = combined_csv['date(yyyyMMddHHmmss)'].apply(lambda t : datetime.strptime(str(t),'%Y%m%d%H%M%S').strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "combined_csv = combined_csv.drop(['date(yyyyMMddHHmmss)'], axis='columns')\n",
    "\n",
    "posts = combined_csv[combined_csv['type'] == 'mbdata']\n",
    "\n",
    "posts.to_csv(\"processed/posts.csv\", index=False)\n",
    "\n",
    "reports = combined_csv[combined_csv['type'] == 'ccdata']\n",
    "\n",
    "reports = reports.drop(['author', 'longitude', 'latitude'], axis='columns')\\\n",
    "    .rename(columns={' location' : 'location'})\n",
    "\n",
    "reports.to_csv(\"processed/reports.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = pd.read_csv(\"processed/posts.csv\") # tweets\n",
    "reports = pd.read_csv(\"processed/reports.csv\") # reports (emergency calls)\n",
    "combined_csv = pd.read_csv(\"processed/combined_csv.csv\") # csv containing the three periods (1700-1830, 1831-2000, 2001-2131)\n",
    "coordinates = pd.read_json(\"abilaMap_processed/coordinates.json\") # mapping from location to coordinates "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
